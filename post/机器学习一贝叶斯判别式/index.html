<!DOCTYPE html>
<html lang="en-us">
	<head>
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="author" content="Chenjing Ding">
<meta name="description" content="Describe your website">
<meta name="generator" content="Hugo 0.37.1" />
<title>机器学习（一）贝叶斯判别式</title>
<link rel="shortcut icon" href="https://mickeyding.github.io/images/favicon.ico">
<link rel="stylesheet" href="https://mickeyding.github.io/css/style.css">
<link rel="stylesheet" href="https://mickeyding.github.io/css/highlight.css">



<link rel="stylesheet" href="https://mickeyding.github.io/css/monosocialiconsfont.css">



<link href="https://mickeyding.github.io/index.xml" rel="alternate" type="application/rss+xml" title="Chenjing Blog" />


<meta property="og:title" content="机器学习（一）贝叶斯判别式" />
<meta property="og:description" content="符号 含义     $C_k$ 第k类   p 概率密度   $P(C_k)$ 第k类的概率。本文中的概率密度和概率在公式推导时已严格区分   x 输入数据；可为训练样本（已知类别）或者待分类数据（未知类别）,为变量   $q$ 输入数据，有固定取值，非变量   m 类型总数    一.三个基本概率 1.1先验概率 根据经验得到的概率。比如$P(C_k)$：第k类的先验概率
1.2条件概率 $P（x|C_k）$: 在第k类中产生观察到的数据x的概率，表示了x是由第k类产生的可能性。
1.3后验概率 $P（C_k|x）$:输入数据x是第k类的概率。
1.4 三者关系 $$p(x,C_k) = p(x|C_k)*P(C_k) = P(C_k|x)p(x)$$
其中x是连续随机变量，注意$P(x) = 0$；表达式中采用的是概率密度函数。 $C$是离散随机变量，表达式中采用的是概率。
 1.具体参考Christopher M. Bishop，Pattern Recognition and Machine Learning，Springer, 2006 1.2.1节。
2.在第二节4.3生成模型和判别模型的比较中再来比较条件概率和后验概率。
 二.贝叶斯判别式最佳决策准测的推导 目标函数： 使错分输入数据x的概率最小。 $$图1 贝叶斯判别式最小化错分概率$$ 已知决策准测$x_0$, 当$x &lt; x_0$，即$x \in R_1$，贝叶斯决策认为x属于$C_1$类，反之则为$C_2类。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://mickeyding.github.io/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%80%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%A4%E5%88%AB%E5%BC%8F/" />



<meta property="article:published_time" content="2018-02-13T16:30:37&#43;08:00"/>

<meta property="article:modified_time" content="2018-02-13T16:30:37&#43;08:00"/>













<meta itemprop="name" content="机器学习（一）贝叶斯判别式">
<meta itemprop="description" content="符号 含义     $C_k$ 第k类   p 概率密度   $P(C_k)$ 第k类的概率。本文中的概率密度和概率在公式推导时已严格区分   x 输入数据；可为训练样本（已知类别）或者待分类数据（未知类别）,为变量   $q$ 输入数据，有固定取值，非变量   m 类型总数    一.三个基本概率 1.1先验概率 根据经验得到的概率。比如$P(C_k)$：第k类的先验概率
1.2条件概率 $P（x|C_k）$: 在第k类中产生观察到的数据x的概率，表示了x是由第k类产生的可能性。
1.3后验概率 $P（C_k|x）$:输入数据x是第k类的概率。
1.4 三者关系 $$p(x,C_k) = p(x|C_k)*P(C_k) = P(C_k|x)p(x)$$
其中x是连续随机变量，注意$P(x) = 0$；表达式中采用的是概率密度函数。 $C$是离散随机变量，表达式中采用的是概率。
 1.具体参考Christopher M. Bishop，Pattern Recognition and Machine Learning，Springer, 2006 1.2.1节。
2.在第二节4.3生成模型和判别模型的比较中再来比较条件概率和后验概率。
 二.贝叶斯判别式最佳决策准测的推导 目标函数： 使错分输入数据x的概率最小。 $$图1 贝叶斯判别式最小化错分概率$$ 已知决策准测$x_0$, 当$x &lt; x_0$，即$x \in R_1$，贝叶斯决策认为x属于$C_1$类，反之则为$C_2类。">


<meta itemprop="datePublished" content="2018-02-13T16:30:37&#43;08:00" />
<meta itemprop="dateModified" content="2018-02-13T16:30:37&#43;08:00" />
<meta itemprop="wordCount" content="185">



<meta itemprop="keywords" content="Machine Learning,Bayes discriminant function," />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="机器学习（一）贝叶斯判别式"/>
<meta name="twitter:description" content="符号 含义     $C_k$ 第k类   p 概率密度   $P(C_k)$ 第k类的概率。本文中的概率密度和概率在公式推导时已严格区分   x 输入数据；可为训练样本（已知类别）或者待分类数据（未知类别）,为变量   $q$ 输入数据，有固定取值，非变量   m 类型总数    一.三个基本概率 1.1先验概率 根据经验得到的概率。比如$P(C_k)$：第k类的先验概率
1.2条件概率 $P（x|C_k）$: 在第k类中产生观察到的数据x的概率，表示了x是由第k类产生的可能性。
1.3后验概率 $P（C_k|x）$:输入数据x是第k类的概率。
1.4 三者关系 $$p(x,C_k) = p(x|C_k)*P(C_k) = P(C_k|x)p(x)$$
其中x是连续随机变量，注意$P(x) = 0$；表达式中采用的是概率密度函数。 $C$是离散随机变量，表达式中采用的是概率。
 1.具体参考Christopher M. Bishop，Pattern Recognition and Machine Learning，Springer, 2006 1.2.1节。
2.在第二节4.3生成模型和判别模型的比较中再来比较条件概率和后验概率。
 二.贝叶斯判别式最佳决策准测的推导 目标函数： 使错分输入数据x的概率最小。 $$图1 贝叶斯判别式最小化错分概率$$ 已知决策准测$x_0$, 当$x &lt; x_0$，即$x \in R_1$，贝叶斯决策认为x属于$C_1$类，反之则为$C_2类。"/>
<meta name="twitter:site" content="@https://www.twitter.com/"/>


    </head>
<body>
    <nav class="main-nav">
	
		<a href='https://mickeyding.github.io/'> <span class="arrow">←</span>Home</a>
	

	
 		<a href='https://mickeyding.github.io/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%80%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%A4%E5%88%AB%E5%BC%8F/'>机器学习（一）贝叶斯判别式</a>
  	
 		<a href='https://mickeyding.github.io/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BA%8C%E6%A6%82%E7%8E%87%E5%AF%86%E5%BA%A6%E5%88%86%E5%B8%83%E4%B9%8B%E9%9D%9E%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/'>机器学习（二）概率密度估计之非参数估计 </a>
  	
 		<a href='https://mickeyding.github.io/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BA%8C%E6%A6%82%E7%8E%87%E5%AF%86%E5%BA%A6%E5%88%86%E5%B8%83%E4%B9%8B%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86%E5%92%8C%E6%89%80%E7%94%A8%E7%AC%A6%E5%8F%B7/'>机器学习（二）概率密度分布之预备知识和所用符号 </a>
  	

	
		<a class="cta" href="https://mickeyding.github.io/index.xml">Subscribe</a>
	
</nav>

    <section id="wrapper">
        
        
<article class="post">
    <header>
        <h1>机器学习（一）贝叶斯判别式</h1>
        <h2 class="subtitle"></h2>
        <h2 class="headline">
        February 13, 2018
        <br>
        
        
            
                <a href="https://mickeyding.github.io/tags/machine-learning">Machine Learning</a>
            
                <a href="https://mickeyding.github.io/tags/bayes-discriminant-function">Bayes discriminant function</a>
            
        
        
        </h2>
    </header>
    <section id="post-body">
        

<hr />

<table>
<thead>
<tr>
<th>符号</th>
<th>含义</th>
</tr>
</thead>

<tbody>
<tr>
<td>$C_k$</td>
<td>第k类</td>
</tr>

<tr>
<td>p</td>
<td>概率密度</td>
</tr>

<tr>
<td>$P(C_k)$</td>
<td>第k类的概率。本文中的概率密度和概率在公式推导时已严格区分</td>
</tr>

<tr>
<td>x</td>
<td>输入数据；可为训练样本（已知类别）或者待分类数据（未知类别）,为变量</td>
</tr>

<tr>
<td>$q$</td>
<td>输入数据，有固定取值，非变量</td>
</tr>

<tr>
<td>m</td>
<td>类型总数</td>
</tr>
</tbody>
</table>

<hr />

<h2 id="一-三个基本概率">一.三个基本概率</h2>

<h3 id="1-1先验概率">1.1先验概率</h3>

<p>根据经验得到的概率。比如$P(C_k)$：第k类的先验概率</p>

<h3 id="1-2条件概率">1.2条件概率</h3>

<p>$P（x|C_k）$: 在第k类中产生观察到的数据x的概率，表示了x是由第k类产生的可能性。</p>

<h3 id="1-3后验概率">1.3后验概率</h3>

<p>$P（C_k|x）$:输入数据x是第k类的概率。</p>

<h3 id="1-4-三者关系">1.4 三者关系</h3>

<p>$$p(x,C_k) = p(x|C_k)*P(C_k) = P(C_k|x)p(x)$$</p>

<p>其中x是连续随机变量，注意$P(x) = 0$；表达式中采用的是概率密度函数。
$C$是离散随机变量，表达式中采用的是概率。</p>

<blockquote>
<p>1.具体参考Christopher M. Bishop，Pattern Recognition and Machine Learning，Springer, 2006 1.2.1节。<br />
2.在第二节4.3生成模型和判别模型的比较中再来比较条件概率和后验概率。</p>
</blockquote>

<h2 id="二-贝叶斯判别式最佳决策准测的推导">二.贝叶斯判别式最佳决策准测的推导</h2>

<p><strong>目标函数：</strong>
使错分输入数据x的概率最小。
<img src="http://img.blog.csdn.net/2018021622312950?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMjYzODY3MDc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=" 图1 贝叶斯判别式最小化错分概率 " />
 $$图1 贝叶斯判别式最小化错分概率$$
已知决策准测$x_0$, 当$x &lt; x_0$，即$x \in R_1$，贝叶斯决策认为x属于$C_1$类，反之则为$C_2类。</p>

<p>$$P（mistake）= P（x\in R_ 1,C_2 ）+ P(x\in R_2,C1) \\ = \int_{R_1} p(x,C_2) dx + \int_{R_2} p(x,C_1) dx  \\ = \int_{R_1} P(C_2|x)*p(x) dx+ \int_{R_2} P(C_1|x)*p(x) dx $$</p>

<p>观察上图，当决策准则为$\widehat{x}$，P(mistake)是红色，绿色和蓝色的面积和。当决策准则为$x_0$，P(mistake)是绿色和蓝色的面积和。要使P(mistake)的概率最小，应使红色面积部分最小。当$p（x,C_1）= p(x,C_2)$时，红色部分面积为0；即分界线为 $\{ x|\ p(x,C_1)=p(x,C_2) \}$ 。</p>

<p><strong>最佳决策准测：</strong>
根据上述分界线，当$P(C_1|x)*p(x) &gt;P(C_2|x)*p(x)$,贝叶斯决策将x分为$C_1$类;
即：$p(x|C_1)*P(C_1) &gt;p(x|C_2)*P(C_2)$</p>

<p>$$\frac{p(x|C_1)}{p(x|C_2)} &gt; \frac{P(C_2)}{P(C_1)}$$其中$\frac{P(C_2)}{P(C_1)}$称为<strong>决策阈值</strong>。</p>

<h2 id="三-损失函数在贝叶斯判别式中的的应用">三.损失函数在贝叶斯判别式中的的应用</h2>

<h3 id="3-1贝叶斯决策损失函数的定义">3.1贝叶斯决策损失函数的定义</h3>

<p>$L_{kj}（0&lt;k, j&lt;=m）$: 如果x被分类到第j类，而其实x是第k类的损失值。损失矩阵就是由这些损失值构成的矩阵。</p>

<h3 id="3-2带损失函数的最佳决策准测">3.2带损失函数的最佳决策准测</h3>

<h4 id="3-2-1-损失函数的期望">3.2.1 损失函数的期望</h4>

<p>条件损失函数期望:<br />
$R(a_j|q):$对于一个特定的q输入，采取决策$a_j$的损失期望，也叫做条件风险。
$$R(a_j|q) = \sum_{k=1}^m L_{kj} P(C_k|q)$$</p>

<p>损失期望<br />
R：对于所有决策总的损失期望。</p>

<p>$$ R = \sum_{k=1}^m \sum_{j=1}^m \int_{R_j} L_{kj} p(x,C_k) dx<br />
\\ = \sum_{j=1}^m \int_{R_j} [ \sum_{k=1}^m L_{kj}P(C_k|x) ]p(x) dx
\\ = \sum_{j=1}^m \int_{R_j} R(a_j|x) p(x) dx
\\ = E(R(a_j|q )) $$</p>

<h4 id="3-2-2-目标函数">3.2.2 目标函数</h4>

<p>对于给定输入q，选择条件风险最小的决策，可使总的损失期望最小。
以两类为例：
假设有两个类$C_1,C_2$，有两个决策$a_1，a_2$。损失函数 $L(a_j|C_k) = L_{kj}$。</p>

<p>$$R(a_1|x) = L_{11}*P(C_1|x)+L_{21}P(C_2|x) \\ R(a_2|x)=L_{12}*P(C_1|x)+ L_{22} P(C_2|x)$$</p>

<p>如果$ R(a_2|x)&gt;R(a_1|x)$，选择a1。
$$L_{12}*P(C_1|x)+ L_{22} P(C_2|x) &gt; L_{11}*P(C_1|x)+L_{21}P(C_2|x)
\\ \frac {L_{12} - L_{11}}{L_{21} - L_{22}} &gt; \frac{P(C_2|x)}{P(C_1|x)} = \frac{p(x|C_2)P(C_2)}{p(x|C_1)P(C_1)}
\\ \frac{p(x|C_1)}{p(x|C_2)} &gt; \frac {P(C_2)(L_{21} - L_{22})}{P(C_1)(L_{12} - L_{11})} $$
上式即为考虑损失函数的贝叶斯最佳决策准则。</p>

    </section>
</article>

<footer id="post-meta" class="clearfix">
    <a href="https://twitter.com/Your%20Twitter%20account">
    <img class="avatar" src="https://mickeyding.github.io/images/avatar.png">
    <div>
        <span class="dark">Chenjing Ding</span>
        <span>I&#39;m an blogger.</span>
    </div>
    </a>
    <section id="sharing">
        <a class="twitter" href="https://twitter.com/intent/tweet?text=https%3a%2f%2fmickeyding.github.io%2fpost%2f%25E6%259C%25BA%25E5%2599%25A8%25E5%25AD%25A6%25E4%25B9%25A0%25E4%25B8%2580%25E8%25B4%259D%25E5%258F%25B6%25E6%2596%25AF%25E5%2588%25A4%25E5%2588%25AB%25E5%25BC%258F%2f - %e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%ef%bc%88%e4%b8%80%ef%bc%89%e8%b4%9d%e5%8f%b6%e6%96%af%e5%88%a4%e5%88%ab%e5%bc%8f by @Your%20Twitter%20account"><span class="icon-twitter"> tweet</span></a>

<a class="facebook" href="#" onclick="
    window.open(
      'https://www.facebook.com/sharer/sharer.php?u='+encodeURIComponent(location.href),
      'facebook-share-dialog',
      'width=626,height=436');
    return false;"><span class="icon-facebook-rect"> Share</span>
</a>

    </section>
</footer>

<div id="disqus_thread"></div>
<script>
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "spf13" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

<ul id="post-list" class="archive readmore">
    <h3>Read more</h3>

    
    
    
        <li>
            <a href="https://mickeyding.github.io/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BA%8C%E6%A6%82%E7%8E%87%E5%AF%86%E5%BA%A6%E5%88%86%E5%B8%83%E4%B9%8B%E9%9D%9E%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/">机器学习（二）概率密度估计之非参数估计 <aside class="dates">Feb 19 2018</aside></a>
        </li>
    
        <li>
            <a href="https://mickeyding.github.io/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BA%8C%E6%A6%82%E7%8E%87%E5%AF%86%E5%BA%A6%E5%88%86%E5%B8%83%E4%B9%8B%E9%A2%84%E5%A4%87%E7%9F%A5%E8%AF%86%E5%92%8C%E6%89%80%E7%94%A8%E7%AC%A6%E5%8F%B7/">机器学习（二）概率密度分布之预备知识和所用符号 <aside class="dates">Feb 19 2018</aside></a>
        </li>
    
</ul>



        <footer>
  <div>
    <p>
    &copy; 2017-18 Chenjing Ding.
   
    </p>
  </div>
  <script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
  });
  MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });

 
</script>
</footer>


</script>
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-XYSYXYSY-X']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script');
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' :
        'http://www') + '.google-analytics.com/ga.js';
    ga.setAttribute('async', 'true');
    document.documentElement.firstChild.appendChild(ga);
  })();

</script>
</body>
</html>
    </section>
    <script src="//ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js"></script>
<script src="https://mickeyding.github.io/js/main.js"></script>
<script src="https://mickeyding.github.io/js/highlight.js"></script>
<script>hljs.initHighlightingOnLoad();</script>





</body>
</html>
